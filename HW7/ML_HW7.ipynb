{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_HW7.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRio_Gwf8HuK"
      },
      "source": [
        "# Q10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-nFv8m6xTEr"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as K\n",
        "from tensorflow.keras import layers as L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI6M1j2OxvhH"
      },
      "source": [
        "data = K.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2-ciJKjxijb"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = data\n",
        "X_train = X_train.astype(float) / 255.0\n",
        "X_test = X_test.astype(float) / 255.0\n",
        "\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]\n",
        "\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "num_classes = len(set(y_train))\n",
        "\n",
        "y_train = K.utils.to_categorical(y_train, num_classes)\n",
        "y_test = K.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC1-1iGByrcU"
      },
      "source": [
        "def build_model():\n",
        "    model = K.Sequential()\n",
        "    model.add(L.InputLayer(input_shape=input_shape))\n",
        "    model.add(L.Conv2D(32, 3, 2, activation=\"relu\"))\n",
        "    model.add(L.BatchNormalization())\n",
        "    model.add(L.Conv2D(16, 3, 2,activation=\"relu\"))\n",
        "    model.add(L.BatchNormalization())\n",
        "    # model.add(L.Conv1D(1, 3, 1, activation=\"relu\"))\n",
        "    model.add(L.Flatten())\n",
        "    model.add(L.Dense(10, activation=\"softmax\"))\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK6XuiJP1UDS"
      },
      "source": [
        "model = build_model()\n",
        "print(model.summary())\n",
        "model.compile(\n",
        "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=\"accuracy\"\n",
        ")\n",
        "history = model.fit(x=X_train, y=y_train, epochs=20, validation_split=0.1, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfzvVPGo46ja"
      },
      "source": [
        "print(model.evaluate(x=X_test, y=y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC-IgyPr5vSr"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(2, 1, figsize=(8, 14))\n",
        "plt.sca(axes[0])\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "\n",
        "plt.sca(axes[1])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj_Z9OAe83T0"
      },
      "source": [
        "# Q9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__F83wbD-CtO"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import (StandardScaler, \n",
        "                                   OneHotEncoder, \n",
        "                                   LabelEncoder, \n",
        "                                   FunctionTransformer)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-Q_KkxbF6gC"
      },
      "source": [
        "import os \n",
        "os.environ[\"KAGGLE_CONFIG_DIR\"] = \"/content/drive/MyDrive/kaggle\"\n",
        "!kaggle datasets download -d uciml/forest-cover-type-dataset\n",
        "!unzip forest-cover-type-dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui5Zh4h1GMAT"
      },
      "source": [
        "df = pd.read_csv(\"covtype.csv\")\n",
        "X = df.loc[:, df.columns != 'Cover_Type'].copy()\n",
        "Y = df.loc[:, df.columns == 'Cover_Type'].copy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.30, random_state = 101)\n",
        "\n",
        "y_train = y_train.values.ravel()\n",
        "y_test = y_test.values.ravel()\n",
        "\n",
        "num_vars = [\"Elevation\", \n",
        "            \"Aspect\", \n",
        "            \"Slope\", \n",
        "            \"Horizontal_Distance_To_Hydrology\", \n",
        "            \"Vertical_Distance_To_Hydrology\", \n",
        "            \"Horizontal_Distance_To_Roadways\",\n",
        "            \"Hillshade_9am\", \n",
        "            \"Hillshade_Noon\", \n",
        "            \"Hillshade_3pm\", \n",
        "            \"Horizontal_Distance_To_Fire_Points\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train.loc[:, num_vars])\n",
        "X_train.loc[:, num_vars] = scaler.transform(X_train.loc[:, num_vars])\n",
        "X_test.loc[:, num_vars] = scaler.transform(X_test.loc[:, num_vars])\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abu7o0_fIGoC"
      },
      "source": [
        "pipe = Pipeline([(\"clf\", MLPClassifier(batch_size=256, verbose=True,))])\n",
        "pipe.fit(X_train, y_train)\n",
        "print(accuracy_score(y_test, pipe.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SC_s85uJTlO"
      },
      "source": [
        "pipe = Pipeline([\n",
        "                 (\"pca\", PCA(n_components=0.8)),\n",
        "                 (\"clf\", MLPClassifier(batch_size=256, verbose=True,))\n",
        "                 ])\n",
        "pipe.fit(X_train, y_train)\n",
        "print(accuracy_score(y_test, pipe.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}