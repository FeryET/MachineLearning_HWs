{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "5d3cdb8a7d055c85f7a324b106e89bb24fb8e3b0b6be79db7c2a56b667e1bd6e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.special import gamma, factorial\n",
    "from data.FACES.imageLoader import loadImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AssignmentUtils:\n",
    "    def __init__(self):\n",
    "        self.data_path = \"data\"\n",
    "    \n",
    "    def load_mnist(self, prefix_type):\n",
    "        data_loc = os.path.join(self.data_path, \n",
    "                                \"Reduced Fashion-MNIST\", \n",
    "                                f\"{prefix_type.capitalize()}_Data.csv\")\n",
    "        label_loc = os.path.join(self.data_path, \n",
    "                                \"Reduced Fashion-MNIST\", \n",
    "                                f\"{prefix_type.capitalize()}_Labels.csv\")\n",
    "        \n",
    "        data_df = pd.read_csv(data_loc, index_col=False)\n",
    "        labels = []\n",
    "        with open(label_loc) as lfile:\n",
    "            while True:\n",
    "                line = lfile.readline()\n",
    "                if not line:\n",
    "                    break\n",
    "                labels.append(int(float(line.strip())))\n",
    "        \n",
    "        data = data_df.to_numpy()\n",
    "        data_df = [\n",
    "            {\"image\": d,\n",
    "            \"label\": l} for d, l in zip(data, labels)\n",
    "        ]\n",
    "        data_df = pd.DataFrame(data_df)\n",
    "        return data_df\n",
    "            \n",
    "    def load_faces(self, prefix_type):\n",
    "        folder = os.path.join(self.data, \"FACES\", prefix_type)\n",
    "        return loadImages(folder)\n",
    "\n",
    "\n",
    "assignment_util = AssignmentUtils()\n",
    "\n",
    "mnist_train = assignment_util.load_mnist(\"train\")\n",
    "mnist_test = assignment_util.load_mnist(\"test\")"
   ]
  },
  {
   "source": [
    "# Q8"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DensityEstimator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self._data = X\n",
    "        self.n_features = X.shape[1]\n",
    "    \n",
    "    def _sample_pdf(self, x):\n",
    "        pass\n",
    "        \n",
    "    def pdf(self, X):\n",
    "        return np.array(\n",
    "            [self._sample_pdf(x) for x in X]\n",
    "        )\n",
    "\n",
    "class ParzenDensityEstimator(DensityEstimator):\n",
    "    def __init__(self, window_size):\n",
    "        super().__init__()\n",
    "        self.window_size = window_size\n",
    "    \n",
    "    \n",
    "    def _sample_pdf(self, x):\n",
    "        phi = (np.abs(x - self._data) < self.window_size/2).any(axis=-1).any().astype(float)\n",
    "        return phi / ((self.window_size ** self.n_features) * self._data.shape[0])\n",
    "        \n",
    "\n",
    "class KNNDensityEstimator(DensityEstimator):\n",
    "    def __init__(self, k):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "    \n",
    "    def _sample_pdf(self, x):\n",
    "        dists = np.sqrt(np.power((x - self._data), 2).sum(axis=-1))\n",
    "        max_k_dist = dists[np.argsort(dists)][self.k]\n",
    "        r_n = (max_k_dist ** self.n_features) \n",
    "        coef = (np.pi ** (self.n_features/2)) / gamma(self.n_features/2 + 1)\n",
    "        vol = r_n * coef\n",
    "        return self.k / (self._data.shape[0] * vol)\n",
    "        \n",
    "\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    class PDFEstimatorFactory:\n",
    "        MAPPINGS = {\n",
    "                \"parzen\": ParzenDensityEstimator,\n",
    "                \"knn\": KNNDensityEstimator,\n",
    "        }\n",
    "        @staticmethod\n",
    "        def create(pdf_type, **params):\n",
    "            return NaiveBayesClassifier.PDFEstimatorFactory.MAPPINGS[pdf_type](**params)\n",
    "\n",
    "    def __init__(self, pdf_type, **pdf_estimator_params):\n",
    "        self.pdf_type = pdf_type\n",
    "        self.pdf_estimator_params = pdf_estimator_params\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = sorted(set(y))\n",
    "        self.pdf_estimators = [\n",
    "            NaiveBayesClassifier.PDFEstimatorFactory.create(self.pdf_type, \n",
    "                                       **self.pdf_estimator_params) for c in self.classes_\n",
    "        ]\n",
    "        for idx, c in enumerate(self.classes_):\n",
    "            estimator = self.pdf_estimators[idx]\n",
    "            indices = y == c\n",
    "            estimator.fit(\n",
    "                X[indices]\n",
    "            )\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probs = np.zeros((X.shape[0], len(self.classes_)))\n",
    "        for idx, c in enumerate(self.classes_):\n",
    "            estimator = self.pdf_estimators[idx]\n",
    "            probs[..., idx] = estimator.pdf(X)\n",
    "        labels_idx = probs.argmax(axis=-1)\n",
    "        labels = [self.classes_[l_idx] for l_idx in labels_idx]\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = mnist_train[\"image\"].to_numpy(), mnist_train[\"label\"].to_numpy()\n",
    "X_test, y_test = mnist_test[\"image\"].to_numpy(), mnist_test[\"label\"].to_numpy()\n",
    "\n",
    "X_train = np.array([x for x in X_train])\n",
    "X_test = np.array([x for x in X_test])\n",
    "X_train.shape\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-084a4e9e2c6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-c9f06851ca53>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf_estimators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mlabels_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-c9f06851ca53>\u001b[0m in \u001b[0;36mpdf\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         return np.array(\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         )\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-c9f06851ca53>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         return np.array(\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         )\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-c9f06851ca53>\u001b[0m in \u001b[0;36m_sample_pdf\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sample_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mphi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mphi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "w_sizes = [0.2, 0.5, 0.7]\n",
    "\n",
    "\n",
    "clf = NaiveBayesClassifier(\n",
    "    \"parzen\", window_size=w_sizes[0]\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "preds = clf.predict(X_test)"
   ]
  }
 ]
}